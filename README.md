# Deep_Neural_Networks_with_PyTorch

By IBM on Coursera

--------------------------------------------------------------------------------------------------------------------------------------------------------

1. Week 1: Tensor and Datasets </br>
                * Lab Tensors 1D (TorchTensorsIn1D.ipynb)
                * Lab Two-Dimensional Tensors (Two-DimensionalTensors.ipynb)
                * Lab Differentiation in PyTorch (DifferentiationInPyTorch.ipynb)
                * Lab Simple Data Set (SimpleDataset.ipynb)
                * Lab Data Set (ImageDatasetsAndTransforms.ipynb)
                * Lab Torch Vision Datasets (PrebuiltDatasetsAndTransforms.ipynb)

2. Week 2: Linear Regression </br>
                * Lab Linear Regression 1D: Prediction (LinearRegression1D:Prediction.ipynb)
                * Lab Linear Regression 1D: Prediction (LinearRegression1D:TrainingOneParameter.ipynb)
                * Lab Linear Regression: Prediction (LinearRegression1D:TrainingTwoParameter.ipynb)
                * Lab Linear Regression 1D: PredictionStochastic Gradient Descent and the Data Loader (LinearRegression1D:TrainingTwoParameterStochasticGradientDescent(SGD).ipynb)
                * Mini-Batch Gradient Descent (LinearRegression1D:TrainingTwoParameterMini-BatchGradientDecent.ipynb)
                * Linear Regression 1D PyTroch (LinearRegression1D:TrainingTwoParameterMini-BatchGradientDescent.ipynb)
                * Training, Validation and Test Split in PyTorch (LinearRegression:TrainingAndValidationData.ipynb)

3. Week 3: Multiple Input Output Linear Regression - Logistic Regression for Classification </br>
                * Multiple Linear Regression Prediction (MultipleLinearRegression.ipynb)
                * Multiple Linear Regression Training (LinearRegressionMultipleOutputs1.ipynb)
                * Multiple Linear Regression Prediction (LinearRegressionWithMultipleOutputs.ipynb)
                * Multiple Linear Regression Training (LinearRegressionMultipleOutputs1.ipynb)
                * Logistic Regression Prediction (LogisticRegression.ipynb)
                * Logistic Regression Mean Square Error (LogisticRegressionAndBadInitializationValue.ipynb)
                * Logistic Regression Cross Entropy (LogisticRegressionTrainingNegativeLogLikelihood(Cross-Entropy).ipynb)

4. Week 4: Softmax Regression - Shallow Neural Networks </br>
                * Softmax Classifier 1 (SoftmaxClassifier1D.ipynb)
                * Softmax Classifier 2 (SoftmaxClassifier.ipynb)
                * Neural Networks in One Dimension (SimpleOneHiddenLayerNeuralNetwork.ipynb)
                * More Hidden Neurons (NeuralNetworksMoreHiddenNeurons.ipynb)
                * Multidimensional Neural Network (NeuralNetworksWithOneHiddenLayer:NoisyXOR.ipynb)
                * Multi-Class Neural Networks with MNIST (NeuralNetworksWithOneHiddenLayer.ipynb)
                * Activation Functions (ActivationFunctions.ipynb)
                * Neural Network with Different Activation Functions (TestSigmoid,TanhAndReluActivationsFunctionsOnTheMNISTDataset.ipynb)

5. Week 5: Deep Networks </br>
                * Deep Neural Networks (HiddenLayerDeepNetwork:Sigmoid,TanhAndReluActivationsFunctionsMNISTDataset.ipynb)
                * Deeper Neural Networks : nn.ModuleList() (DeeperNeuralNetworksWith_nn.ModuleList().ipynb)
                * Dropout Classification (UsingDropoutForClassification.ipynb)
                * Dropout regression (UsingDropoutInRegression.ipynb)
                *
                
6. Week 6: Convolutional Neural Networks </br>
                *
                
7. Week 7: Peer Review </br>
                *


* Week 5: </br>
        * Final Project N째1      
        * Final Project N째2        
        * Final Project N째3        
        * Final Project N째4
